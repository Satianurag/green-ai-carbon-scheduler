# üìã Data Card

## What We're Measuring

**Purpose:** Demonstrate carbon-aware ML scheduling with measurable energy/CO‚ÇÇ reduction.

**Task:** Regression (predict continuous values) to show model efficiency tradeoffs.

## Data Sources

### Default: California Housing (via scikit-learn)
- **Size:** 1,200 samples, 8 features
- **License:** BSD (open source)
- **Why:** Public dataset, reproducible, no privacy concerns
- **Limitations:** Small size means fast training (good for demo, hits sensor limits)

### Optional: Kaggle Competition Data
- **Source:** Hack4Earth Green AI Competition
- **License:** CC BY 4.0
- **Format:** `train.csv` with target column
- **Note:** Scaffold dataset (minimal features) to enable submissions

## Preprocessing

**Standard ML pipeline:**
- Numeric features ‚Üí StandardScaler (zero mean, unit variance)
- Categorical features ‚Üí OneHotEncoder (binary columns)
- Missing values ‚Üí Forward fill or drop

**Deterministic:** `random_state=42` ensures identical preprocessing across baseline/optimized runs.

## Fitness for Purpose

### ‚úÖ What This Data IS Good For:
- Proving carbon measurement methodology
- Demonstrating carbon-aware scheduling
- Showing model efficiency tradeoffs
- Reproducible benchmarking

### ‚ö†Ô∏è What This Data IS NOT:
- Representative of production workloads (too small)
- Domain-specific sustainability problem
- Long-running training (seconds vs hours)

**For production:** Replace with your domain data. Architecture scales to larger datasets, GPUs, longer training.

## Ethics & Bias

- ‚úÖ No PII (personally identifiable information)
- ‚úÖ No sensitive attributes (race, gender, etc.)
- ‚úÖ Open license (free to use, modify, distribute)
- ‚úÖ Environmental focus (reduce AI carbon footprint)
- ‚ö†Ô∏è Measurement bias: Ultra-short runtimes hit sensor precision limits (see FOOTPRINT.md)
