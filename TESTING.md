# ğŸ§ª Testing Guide for Green AI Carbon Scheduler

## Overview

This project now includes a comprehensive test suite covering:
- **Unit tests**: Individual module functionality
- **Integration tests**: End-to-end workflows
- **Mocked tests**: No external dependencies (API, internet)
- **Edge case coverage**: Error handling, boundary conditions

## ğŸ“Š Test Coverage

### Current Coverage by Module

| Module | Unit Tests | Coverage | Test File |
|--------|-----------|----------|-----------|
| **ci_provider.py** | 20+ tests | ~90% | `tests/test_ci_provider.py` |
| **scheduler.py** | 11 tests | ~95% | `tests/test_scheduler.py` |
| **measure.py** | 14 tests | ~90% | `tests/test_measure.py` |
| **pipeline.py** | 18+ tests | ~85% | `tests/test_pipeline.py` |
| **metrics.py** | 11 tests | ~80% | `tests/test_metrics.py` |
| **plots.py** | 7 tests | ~85% | `tests/test_plots.py` |
| **Integration** | 10+ tests | N/A | `tests/test_integration.py` |

**Total: 90+ test cases** covering critical functionality.

---

## ğŸš€ Quick Start

### 1. Install Test Dependencies

```bash
pip install -r requirements-test.txt
```

This installs:
- `pytest` - Testing framework
- `pytest-cov` - Coverage reporting
- `pytest-mock` - Mocking utilities
- `requests-mock` - HTTP mocking

### 2. Run All Tests

```bash
# Run all tests with coverage
pytest

# Run with verbose output
pytest -v

# Run specific test file
pytest tests/test_ci_provider.py

# Run specific test class
pytest tests/test_scheduler.py::TestShouldRun

# Run specific test
pytest tests/test_measure.py::TestEnergyCO2Proxy::test_basic_calculation
```

### 3. View Coverage Report

```bash
# Terminal report (generated automatically)
pytest --cov=src/greenai --cov-report=term-missing

# HTML report (open in browser)
pytest --cov=src/greenai --cov-report=html
open htmlcov/index.html
```

---

## ğŸ“ Test Structure

```
tests/
â”œâ”€â”€ __init__.py                 # Test package initialization
â”œâ”€â”€ test_ci_provider.py         # Carbon intensity provider tests
â”œâ”€â”€ test_scheduler.py           # Scheduling logic tests
â”œâ”€â”€ test_measure.py             # Energy measurement tests
â”œâ”€â”€ test_pipeline.py            # ML pipeline tests
â”œâ”€â”€ test_metrics.py             # Metrics collection tests
â”œâ”€â”€ test_plots.py               # Visualization tests
â””â”€â”€ test_integration.py         # End-to-end workflow tests
```

---

## ğŸ”¬ Test Categories

### Unit Tests

**Purpose**: Test individual functions and classes in isolation.

**Examples**:
```bash
# Test carbon intensity fetching
pytest tests/test_ci_provider.py::TestFetchUKCurrentCI -v

# Test energy calculations
pytest tests/test_measure.py::TestEnergyCO2Proxy -v

# Test model building
pytest tests/test_pipeline.py::TestBuildModels -v
```

### Integration Tests

**Purpose**: Test complete workflows and module interactions.

**Examples**:
```bash
# Test complete training workflow
pytest tests/test_integration.py::TestEndToEndWorkflow -v

# Test Kaggle submission workflow
pytest tests/test_integration.py::test_kaggle_submission_workflow -v
```

### Smoke Tests (Legacy)

**Purpose**: Quick sanity checks for basic functionality.

```bash
# Original smoke tests (still functional)
python test_smoke.py
```

---

## ğŸ›¡ï¸ What's Tested

### 1. Carbon Intensity Provider (`test_ci_provider.py`)

âœ… Live API integration (mocked)  
âœ… Forecast fallback when actual is None  
âœ… HTTP error handling  
âœ… Timeout handling  
âœ… CSV parsing  
âœ… Low-CI window selection  
âœ… Horizon-based selection  
âœ… Region filtering  
âœ… Edge cases (empty data, missing columns)

### 2. Scheduler (`test_scheduler.py`)

âœ… Threshold-based decisions  
âœ… Below/above/at threshold scenarios  
âœ… Decision structure validation  
âœ… Timestamp format verification  
âœ… API failure propagation  
âœ… Custom threshold values  
âœ… Edge cases (zero threshold, high/low CI)

### 3. Measurement (`test_measure.py`)

âœ… Energy/CO2 proxy calculations  
âœ… Runtime measurement accuracy  
âœ… CodeCarbon integration (mocked)  
âœ… Proxy fallback when CodeCarbon unavailable  
âœ… Function kwargs support  
âœ… Exception propagation  
âœ… Edge cases (zero runtime, custom power)

### 4. Pipeline (`test_pipeline.py`)

âœ… CSV data loading  
âœ… California Housing dataset  
âœ… Synthetic data fallback  
âœ… Preprocessing (numeric/categorical)  
âœ… Baseline vs optimized models  
âœ… LightGBM integration  
âœ… Feature selection  
âœ… Training reproducibility  
âœ… Prediction workflows  
âœ… Kaggle submission format

### 5. Metrics (`test_metrics.py`)

âœ… Evidence CSV creation  
âœ… CSV structure validation  
âœ… Decision logging to JSON  
âœ… Multiple runs append correctly  
âœ… Custom dataset support  
âœ… Threshold enforcement  
âœ… Notes field handling  
âœ… Invalid mode error handling

### 6. Plots (`test_plots.py`)

âœ… Plot file creation  
âœ… Output directory creation  
âœ… Multiple runs aggregation  
âœ… Missing file error handling  
âœ… Malformed data handling  
âœ… Path validation

### 7. Integration (`test_integration.py`)

âœ… Baseline â†’ Optimized â†’ Plotting workflow  
âœ… Scheduler decision making  
âœ… Kaggle submission workflow  
âœ… CSV-based CI workflow  
âœ… Decision logging across runs  
âœ… API failure handling  
âœ… Data consistency  
âœ… Random seed reproducibility

---

## ğŸ¯ Running Specific Test Scenarios

### Fast Tests (No External Dependencies)

```bash
# All tests are mocked - no internet required
pytest tests/
```

### Coverage Goals

```bash
# Generate coverage report
pytest --cov=src/greenai --cov-report=term-missing

# Fail if coverage below 80%
pytest --cov=src/greenai --cov-fail-under=80
```

### Parallel Execution (Faster)

```bash
# Run tests in parallel (requires pytest-xdist)
pytest -n auto
```

---

## ğŸ› Debugging Failed Tests

### Verbose Output

```bash
pytest -vv -s tests/test_ci_provider.py
```

### Show Print Statements

```bash
pytest -s tests/
```

### Stop on First Failure

```bash
pytest -x
```

### Run Last Failed Tests

```bash
pytest --lf
```

### Detailed Traceback

```bash
pytest --tb=long
```

---

## âœ… CI/CD Integration

### GitHub Actions Example

```yaml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - run: pip install -r requirements.txt
      - run: pip install -r requirements-test.txt
      - run: pytest --cov=src/greenai --cov-report=xml
      - uses: codecov/codecov-action@v3
```

---

## ğŸ“ˆ Continuous Improvement

### Adding New Tests

1. **Identify untested code**: Check coverage report
2. **Create test file**: Follow naming convention `test_*.py`
3. **Write test cases**: Use descriptive names
4. **Run tests**: Verify they pass
5. **Check coverage**: Ensure coverage increases

### Test Naming Convention

```python
# Good test names
def test_fetch_actual_ci():
    """Test successful fetch with actual intensity value."""
    
def test_api_timeout():
    """Test handling of timeout errors."""

# Bad test names
def test_1():
    """Test something."""
```

---

## ğŸ”§ Troubleshooting

### ModuleNotFoundError

```bash
# Ensure PYTHONPATH is set
export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"
pytest
```

### Import Errors

```bash
# Install in development mode
pip install -e .
```

### Coverage Not Working

```bash
# Reinstall coverage tools
pip install --upgrade pytest-cov coverage
```

---

## ğŸ“š Further Reading

- [pytest documentation](https://docs.pytest.org/)
- [pytest-cov documentation](https://pytest-cov.readthedocs.io/)
- [Testing Best Practices](https://docs.python-guide.org/writing/tests/)

---


**Made with ğŸ’š for reliable, carbon-aware AI**
